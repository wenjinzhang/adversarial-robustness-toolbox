{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./traffic_Data/DATA\"\n",
    "labelfile=\"labels.csv\"\n",
    "batch_size_val=16\n",
    "steps_per_epoch_val=100\n",
    "epochs_val=20\n",
    "imageDimensions=(32,32,3)\n",
    "testratio=0.1\n",
    "validationratio=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected:  58\n",
      "Importing Classes .....\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'traffic_Data/DAT/0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mImporting Classes .....\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(mylist)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     mypics\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39;49mlistdir(\u001b[39m\"\u001b[39;49m\u001b[39mtraffic_Data/DAT/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(count))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m mypics:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wenjin/dev/adversarial-robustness-toolbox/fangping_notes/model.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         current\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(count)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m y)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'traffic_Data/DAT/0'"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "Images=[]\n",
    "Classno=[]\n",
    "mylist=os.listdir(path)\n",
    "print(\"Total Classes Detected: \",len(mylist))\n",
    "noofclasses=len(mylist)\n",
    "print(\"Importing Classes .....\")\n",
    "for i in range(0,len(mylist)):\n",
    "    mypics=os.listdir(\"traffic_Data/DATA/\" + str(count))\n",
    "    for y in mypics:\n",
    "        current=cv2.imread(path+\"/\"+str(count)+\"/\"+ y)\n",
    "        Images.append(current)\n",
    "        Classno.append(count)\n",
    "    print(str(count) + \"/\" + str(noofclasses))\n",
    "    count=count+1\n",
    "print(str(noofclasses)+(\"/\")+str(noofclasses))\n",
    "print(\"==============================\")\n",
    "print(Images)\n",
    "print(Classno)\n",
    "Images=np.array(Images)\n",
    "Classno=np.array(Classno)\n",
    "print(Images.shape)\n",
    "print(Classno.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Images,Classno,test_size=testratio)\n",
    "X_train, X_validation ,Y_train, Y_validation = train_test_split(X_train,Y_train,test_size=validationratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "print(\"DATA SHAPES\")\n",
    "print(\"Train:  \")\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(\"Validation:   \")\n",
    "print(X_validation.shape, Y_validation.shape)\n",
    "print(\"Test:  \")\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "data=pd.read_csv(labelfile)\n",
    "print(\"data_shape\",data.shape,type(data))\n",
    "\n",
    "def grayscale(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img,(100,100)) \n",
    "    return img\n",
    "def equalize(img):\n",
    "    img=cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img=grayscale(img)\n",
    "    img=equalize(img)\n",
    "    img=img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(list(map(preprocessing,X_train)))\n",
    "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
    "X_test=np.array(list(map(preprocessing,X_test)))\n",
    "#cv2.imshow(\"Gray Scale Images: \", X_train[random.randint(0,len(X_train)-1)])\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],100,100,1)\n",
    "X_validation=X_validation.reshape(X_validation.shape[0],100,100,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],100,100,1)\n",
    "\n",
    "datagen=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1,rotation_range=10)\n",
    "datagen.fit(X_train)\n",
    "batches=datagen.flow(X_train,Y_train,batch_size=20)\n",
    "X_batch,Y_batch=next(batches)\n",
    "\n",
    "Y_train=to_categorical(Y_train,noofclasses)\n",
    "Y_validation=to_categorical(Y_validation,noofclasses)\n",
    "Y_test=to_categorical(Y_test,noofclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymodel():\n",
    "    nooffilters=60\n",
    "    sizeoffilters=(5,5)\n",
    "    sizeoffilters2=(3,3)\n",
    "    sizeofpool=(2,2)\n",
    "    noofnodes=500\n",
    "    model=Sequential()\n",
    "    model.add((Conv2D(nooffilters,sizeoffilters,input_shape=(100,100,1),activation='relu')))\n",
    "    model.add((Conv2D(nooffilters,sizeoffilters,activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeofpool))\n",
    "\n",
    "    model.add((Conv2D(nooffilters//2,sizeoffilters2,activation='relu')))\n",
    "    model.add((Conv2D(nooffilters//2,sizeoffilters2,activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeofpool))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(noofnodes,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(noofclasses,activation='softmax'))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=mymodel()\n",
    "history=model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size_val),steps_per_epoch=steps_per_epoch_val,epochs=100,validation_data=(X_validation,Y_validation),shuffle=1)\n",
    "score=model.evaluate(X_test,Y_test,verbose=0)\n",
    "print('Test Score: ',score[0])\n",
    "print('Test Accuracy: ',score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0628398c3fc4a65cdb75fa1dcd6b7c9b3e28e06e89bb0fd476305f3424b95ff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
