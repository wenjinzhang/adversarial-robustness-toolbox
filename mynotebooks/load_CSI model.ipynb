{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pickle\n",
    "file = open(\"./dataset/datset2.pickle\",'rb')\n",
    "(X_train, Y_train ,X_valid, Y_valid) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 200, 52)\n",
      "6.32168560595898\n",
      "-7.282518964160932\n",
      "4.177067887908362\n",
      "-6.759076232265535\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.max(X_train))\n",
    "print(np.min(X_train))\n",
    "print(np.max(X_valid))\n",
    "print(np.min(X_valid))\n",
    "min_value, max_value = np.min(X_train), np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,  Dropout, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], 52))))\n",
    "model.add(Bidirectional(LSTM(units = 200)))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "# train\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 99 samples\n",
      "Epoch 1/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 1.0270 - accuracy: 0.6579 - val_loss: 0.9560 - val_accuracy: 0.6364\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.8960 - accuracy: 0.7105 - val_loss: 0.8268 - val_accuracy: 0.7172\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 7s 31ms/sample - loss: 0.7728 - accuracy: 0.7807 - val_loss: 0.6996 - val_accuracy: 0.7879\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.6643 - accuracy: 0.8377 - val_loss: 0.5838 - val_accuracy: 0.8586\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.5658 - accuracy: 0.8728 - val_loss: 0.4892 - val_accuracy: 0.8889\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.4855 - accuracy: 0.8860 - val_loss: 0.4134 - val_accuracy: 0.8990\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.4219 - accuracy: 0.8904 - val_loss: 0.3563 - val_accuracy: 0.8990\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.3644 - accuracy: 0.8991 - val_loss: 0.3041 - val_accuracy: 0.9091\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.3171 - accuracy: 0.9254 - val_loss: 0.2632 - val_accuracy: 0.9192\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 9s 40ms/sample - loss: 0.2785 - accuracy: 0.9254 - val_loss: 0.2323 - val_accuracy: 0.9293\n",
      "Epoch 11/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.2461 - accuracy: 0.9298 - val_loss: 0.2087 - val_accuracy: 0.9293\n",
      "Epoch 12/30\n",
      "228/228 [==============================] - 9s 39ms/sample - loss: 0.2205 - accuracy: 0.9342 - val_loss: 0.1895 - val_accuracy: 0.9293\n",
      "Epoch 13/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.1973 - accuracy: 0.9342 - val_loss: 0.1741 - val_accuracy: 0.9394\n",
      "Epoch 14/30\n",
      "228/228 [==============================] - 8s 36ms/sample - loss: 0.1754 - accuracy: 0.9474 - val_loss: 0.1570 - val_accuracy: 0.9495\n",
      "Epoch 15/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.1587 - accuracy: 0.9518 - val_loss: 0.1420 - val_accuracy: 0.9596\n",
      "Epoch 16/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.1398 - accuracy: 0.9561 - val_loss: 0.1292 - val_accuracy: 0.9596\n",
      "Epoch 17/30\n",
      "228/228 [==============================] - 7s 33ms/sample - loss: 0.1221 - accuracy: 0.9561 - val_loss: 0.1183 - val_accuracy: 0.9596\n",
      "Epoch 18/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.1037 - accuracy: 0.9737 - val_loss: 0.1061 - val_accuracy: 0.9596\n",
      "Epoch 19/30\n",
      "228/228 [==============================] - 8s 36ms/sample - loss: 0.0882 - accuracy: 0.9781 - val_loss: 0.0946 - val_accuracy: 0.9697\n",
      "Epoch 20/30\n",
      "228/228 [==============================] - 7s 33ms/sample - loss: 0.0743 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9798\n",
      "Epoch 21/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0583 - accuracy: 0.9912 - val_loss: 0.0720 - val_accuracy: 0.9798\n",
      "Epoch 22/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0398 - accuracy: 0.9956 - val_loss: 0.0513 - val_accuracy: 0.9798\n",
      "Epoch 23/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9798\n",
      "Epoch 24/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 25/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
      "Epoch 26/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9899\n",
      "Epoch 27/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9899\n",
      "Epoch 28/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9899\n",
      "Epoch 29/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9899\n",
      "Epoch 30/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64, epochs=30,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_atten_our.hdf5',\n",
    "                                            monitor='val_accuracy',\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=False)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirectio  multiple                 404800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  multiple                 961600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  40100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,406,904\n",
      "Trainable params: 1,406,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019497611668111398, 0.989899]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 98.98989898989899%\n"
     ]
    }
   ],
   "source": [
    "# Create the ART classifier\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_value, max_value), use_logits=False)\n",
    "\n",
    "# Evaluate the ART classifier on benign test examples\n",
    "predictions = classifier.predict(X_valid)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(Y_valid, axis=1)) / len(Y_valid)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# set targeted label\n",
    "target = 2\n",
    "y_test_adv_tar = np.zeros(Y_valid.shape)\n",
    "for i in range(Y_valid.shape[0]):\n",
    "    y_test_adv_tar[i, target] = 1.0\n",
    "\n",
    "print(y_test_adv_tar[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod, CarliniLInfMethod\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=0.4, targeted=True)\n",
    "x_test_adv = attack_fgsm.generate(x=X_valid, y=y_test_adv_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeted_success_rate_test: 70.7 %\n"
     ]
    }
   ],
   "source": [
    "preds_test_adv = np.argmax(classifier.predict(x_test_adv), axis=1) \n",
    "targeted_success_rate_test = np.sum(preds_test_adv == target) / len(X_valid) \n",
    "print('targeted_success_rate_test: {:.1f} %'.format(targeted_success_rate_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 02:15:24.566539: W tensorflow/c/c_api.cc:349] Operation '{name:'sequential_4/bidirectional_4/backward_lstm_4_1/while' id:1557 op device:{requested: '', assigned: ''} def:{{{node sequential_4/bidirectional_4/backward_lstm_4_1/while}} = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, 10323301848418747708, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT], _lower_using_switch_merge=true, _num_original_outputs=46, _read_only_resource_inputs=[8, 9, 10], _stateful_parallelism=false, body=sequential_4_bidirectional_4_backward_lstm_4_1_while_body_2511_rewritten[], cond=sequential_4_bidirectional_4_backward_lstm_4_1_while_cond_2510_rewritten[], output_shapes=[[], [], [], [], [?,200], 13267621086598707494, [], [], [], [], []], parallel_iterations=32](sequential_4/bidirectional_4/backward_lstm_4_1/while/loop_counter, sequential_4/bidirectional_4/backward_lstm_4_1/while/maximum_iterations, sequential_4/bidirectional_4/backward_lstm_4_1/time, sequential_4/bidirectional_4/backward_lstm_4_1/TensorArrayV2_1, sequential_4/bidirectional_4/backward_lstm_4_1/zeros, sequential_4/bidirectional_4/backward_lstm_4_1/zeros_1, sequential_4/bidirectional_4/backward_lstm_4_1/strided_slice_1, sequential_4/bidirectional_4/backward_lstm_4_1/TensorArrayUnstack/TensorListFromTensor, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/kernel, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/recurrent_kernel, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/bias, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_1, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_2, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_3, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_4, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_5, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_6, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_7, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_8, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_9, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_10, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_11, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_12, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_13, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_14, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_15, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_16, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_17, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_18, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_19, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_20, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_21, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_22, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_23, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_24, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_25, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_26, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_27, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_28, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_29, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_30, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_31, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_32, training_2/Adam/gradients/gradients/sequential_4/bidirectional_4/backward_lstm_4_1/while_grad/gradients/TensorArrayV2Read/TensorListGetItem_grad/TensorListElementShape_0/accumulator:0, training_2/Adam/gradients/gradients/sequential_4/bidirectional_4/backward_lstm_4_1/while_grad/gradients/TensorArrayV2Read/TensorListGetItem_grad/TensorListLength_0/accumulator:0)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import TargetedUniversalPerturbation\n",
    "\n",
    "adv_crafter = TargetedUniversalPerturbation(\n",
    "    classifier,\n",
    "    attacker='deepfool',\n",
    "    delta=0.2,\n",
    "    attacker_params={'eps':0.02, 'verbose': True},\n",
    "    max_iter=5,\n",
    "    eps=5.5,\n",
    "    norm=2)\n",
    "\n",
    "x_adv = adv_crafter.generate(x=X_valid, y=y_test_adv_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200, 52)\n",
      "(99, 200, 52)\n",
      "targeted_success_rate_test: 29.3 %\n"
     ]
    }
   ],
   "source": [
    "noise = adv_crafter.noise\n",
    "print(np.shape(noise))\n",
    "print(np.shape(X_valid))\n",
    "rescaled_noise = noise.copy()\n",
    "x_test_adv = X_valid + rescaled_noise*3\n",
    "preds_test_adv = np.argmax(classifier.predict(x_test_adv), axis=1) \n",
    "targeted_success_rate_test = np.sum(preds_test_adv == target) / len(X_valid) \n",
    "print('targeted_success_rate_test: {:.1f} %'.format(targeted_success_rate_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(noise[0,:])\n",
    "print(noise[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, accuracy] = model.evaluate(X_valid, Y_valid)\n",
    "\n",
    "Y_valid_predict = model.predict(X_valid)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(np.argmax(Y_valid_predict, axis=1), np.argmax(Y_valid, axis=1))\n",
    "plot_confusion_matrix(cm = matrix,\n",
    "                      target_names = ['Raise_arm', 'Run', 'Bow', 'Walk'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Universial Perturbation Through Deepfool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import TargetedUniversalPerturbation\n",
    "from art.utils import random_sphere\n",
    "\n",
    "# build targeted UAP\n",
    "classifier = KerasClassifier(model=model)\n",
    "adv_crafter = TargetedUniversalPerturbation(\n",
    "    classifier,\n",
    "    attacker='fgsm',\n",
    "    delta=0.000001,\n",
    "    attacker_params={'targeted':True, 'eps':0.006},\n",
    "    max_iter=10,\n",
    "    eps=5.5,\n",
    "    norm=2)\n",
    "\n",
    "\n",
    "# set target label\n",
    "target = 1\n",
    "y_train_adv_tar = np.zeros(Y_train.shape)\n",
    "for i in range(Y_train.shape[0]):\n",
    "    y_train_adv_tar[i, target] = 1.0\n",
    "\n",
    "# generate noise\n",
    "_ = adv_crafter.generate(X_train, y=y_train_adv_tar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(adv_crafter.noise))\n",
    "# noise = adv_crafter.noise[0,:]\n",
    "\n",
    "# X_train_adv = X_train + noise\n",
    "# X_valid_adv = X_valid + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, accuracy] = model.evaluate(X_dirty, Y_dirty)\n",
    "\n",
    "Y_dirty_predict = model.predict(X_dirty)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(np.argmax(Y_dirty, axis=1), np.argmax(Y_dirty_predict, axis=1))\n",
    "\n",
    "plot_confusion_matrix(cm = matrix,\n",
    "                      target_names = ['Raise_arm', 'Run', 'Bow', 'Walk'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, num_classes = generate_dataset('./usrp_dataset2/training/')\n",
    "\n",
    "norm_X = (X_train- mean)/std\n",
    "\n",
    "[loss, accuracy] = model.evaluate(norm_X, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('DNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_X, dirty_Y, num_classes = generate_dataset('./our_dataset/data/dirty')\n",
    "print(len(dirty_Y))\n",
    "\n",
    "model.evaluate(dirty_X, dirty_Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dirty_X)\n",
    "x = model.predict(dirty_X)\n",
    "print(np.argmax(x, axis=1))\n",
    "print(np.argmax(dirty_Y, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the adversarial sample\n",
    "\n",
    "### Implementing fast gradient sign method\n",
    "The first step is to create perturbations which will be used to distort the original CSI resulting in an adversarial image. As mentioned, for this task, the gradients are taken with respect to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_images, input_labels):\n",
    "\n",
    "  input_image = tf.convert_to_tensor(input_images, dtype=tf.float32)\n",
    "  input_label = tf.convert_to_tensor(input_labels, dtype=tf.float32)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "\n",
    "  fgm_grad= gradient / tf.norm(gradient, ord=2)\n",
    "\n",
    "  return signed_grad, fgm_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the original CSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "original_csis = X_valid\n",
    "original_targets = Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations1, perturbations2 = create_adversarial_pattern(original_csis, original_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_valid, y_valid):\n",
    "    y_pred = model.predict(x_valid)\n",
    "    y_predict = np.argmax(y_pred, axis=1)\n",
    "    y_valid_one = np.argmax(y_valid, axis=1)\n",
    "    accuracy = round(sum([y_ == y for y_, y in zip(y_predict, y_valid_one)])/len(y_valid_one) * 100,2)\n",
    "    print(\"accuracy: {}%\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epss = [];\n",
    "adv_accuracys = [];\n",
    "clean_accuracys = [];\n",
    "for eps in range(0, 11):\n",
    "    adv_x = original_csis\n",
    "    adv_x = adv_x + eps * perturbations1\n",
    "    # compute accuracy\n",
    "    acc = accuracy(adv_x, original_targets)\n",
    "    epss.append(eps/10)\n",
    "    adv_accuracys.append(acc)\n",
    "    clean_accuracys.append(98.46)\n",
    "    print(\"eps: {} ---> adv_acc:{}%\".format(eps, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean1 = plt.plot(epss, clean_accuracys, marker = 'v', linestyle = 'solid', label='Clean')\n",
    "adv1 = plt.plot(epss, adv_accuracys, marker = 'o', linestyle = 'solid', label='FGM')\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('UAP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7560b00439c9a18b07946e07b04233d01c8b203c21d1b1ada294496408168701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
