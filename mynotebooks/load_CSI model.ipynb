{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pickle\n",
    "file = open(\"./dataset/datset2.pickle\",'rb')\n",
    "(X_train, Y_train ,X_valid, Y_valid) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 200, 52)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,  Dropout, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], 52))))\n",
    "model.add(Bidirectional(LSTM(units = 200)))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "# train\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 99 samples\n",
      "Epoch 1/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 1.0270 - accuracy: 0.6579 - val_loss: 0.9560 - val_accuracy: 0.6364\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.8960 - accuracy: 0.7105 - val_loss: 0.8268 - val_accuracy: 0.7172\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 7s 31ms/sample - loss: 0.7728 - accuracy: 0.7807 - val_loss: 0.6996 - val_accuracy: 0.7879\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.6643 - accuracy: 0.8377 - val_loss: 0.5838 - val_accuracy: 0.8586\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.5658 - accuracy: 0.8728 - val_loss: 0.4892 - val_accuracy: 0.8889\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.4855 - accuracy: 0.8860 - val_loss: 0.4134 - val_accuracy: 0.8990\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.4219 - accuracy: 0.8904 - val_loss: 0.3563 - val_accuracy: 0.8990\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.3644 - accuracy: 0.8991 - val_loss: 0.3041 - val_accuracy: 0.9091\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.3171 - accuracy: 0.9254 - val_loss: 0.2632 - val_accuracy: 0.9192\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 9s 40ms/sample - loss: 0.2785 - accuracy: 0.9254 - val_loss: 0.2323 - val_accuracy: 0.9293\n",
      "Epoch 11/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.2461 - accuracy: 0.9298 - val_loss: 0.2087 - val_accuracy: 0.9293\n",
      "Epoch 12/30\n",
      "228/228 [==============================] - 9s 39ms/sample - loss: 0.2205 - accuracy: 0.9342 - val_loss: 0.1895 - val_accuracy: 0.9293\n",
      "Epoch 13/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.1973 - accuracy: 0.9342 - val_loss: 0.1741 - val_accuracy: 0.9394\n",
      "Epoch 14/30\n",
      "228/228 [==============================] - 8s 36ms/sample - loss: 0.1754 - accuracy: 0.9474 - val_loss: 0.1570 - val_accuracy: 0.9495\n",
      "Epoch 15/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.1587 - accuracy: 0.9518 - val_loss: 0.1420 - val_accuracy: 0.9596\n",
      "Epoch 16/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.1398 - accuracy: 0.9561 - val_loss: 0.1292 - val_accuracy: 0.9596\n",
      "Epoch 17/30\n",
      "228/228 [==============================] - 7s 33ms/sample - loss: 0.1221 - accuracy: 0.9561 - val_loss: 0.1183 - val_accuracy: 0.9596\n",
      "Epoch 18/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.1037 - accuracy: 0.9737 - val_loss: 0.1061 - val_accuracy: 0.9596\n",
      "Epoch 19/30\n",
      "228/228 [==============================] - 8s 36ms/sample - loss: 0.0882 - accuracy: 0.9781 - val_loss: 0.0946 - val_accuracy: 0.9697\n",
      "Epoch 20/30\n",
      "228/228 [==============================] - 7s 33ms/sample - loss: 0.0743 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9798\n",
      "Epoch 21/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0583 - accuracy: 0.9912 - val_loss: 0.0720 - val_accuracy: 0.9798\n",
      "Epoch 22/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0398 - accuracy: 0.9956 - val_loss: 0.0513 - val_accuracy: 0.9798\n",
      "Epoch 23/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9798\n",
      "Epoch 24/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 25/30\n",
      "228/228 [==============================] - 8s 35ms/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
      "Epoch 26/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9899\n",
      "Epoch 27/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9899\n",
      "Epoch 28/30\n",
      "228/228 [==============================] - 8s 34ms/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9899\n",
      "Epoch 29/30\n",
      "228/228 [==============================] - 8s 33ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9899\n",
      "Epoch 30/30\n",
      "228/228 [==============================] - 7s 32ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64, epochs=30,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_atten_our.hdf5',\n",
    "                                            monitor='val_accuracy',\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=False)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirectio  multiple                 404800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  multiple                 961600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  40100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,406,904\n",
      "Trainable params: 1,406,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019497611668111398, 0.989899]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjinzhang/opt/anaconda3/envs/UAP/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/wenjinzhang/opt/anaconda3/envs/UAP/lib/python3.8/site-packages/art/estimators/certification/__init__.py:13: UserWarning: PyTorch not found. Not importing DeepZ functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ functionality\")\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjinzhang/opt/anaconda3/envs/UAP/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-08-01 01:41:25.938812: W tensorflow/c/c_api.cc:349] Operation '{name:'sequential_4/bidirectional_4/backward_lstm_4_1/while' id:1557 op device:{requested: '', assigned: ''} def:{{{node sequential_4/bidirectional_4/backward_lstm_4_1/while}} = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, 10323301848418747708, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT], _lower_using_switch_merge=true, _num_original_outputs=46, _read_only_resource_inputs=[8, 9, 10], _stateful_parallelism=false, body=sequential_4_bidirectional_4_backward_lstm_4_1_while_body_2511_rewritten[], cond=sequential_4_bidirectional_4_backward_lstm_4_1_while_cond_2510_rewritten[], output_shapes=[[], [], [], [], [?,200], 13267621086598707494, [], [], [], [], []], parallel_iterations=32](sequential_4/bidirectional_4/backward_lstm_4_1/while/loop_counter, sequential_4/bidirectional_4/backward_lstm_4_1/while/maximum_iterations, sequential_4/bidirectional_4/backward_lstm_4_1/time, sequential_4/bidirectional_4/backward_lstm_4_1/TensorArrayV2_1, sequential_4/bidirectional_4/backward_lstm_4_1/zeros, sequential_4/bidirectional_4/backward_lstm_4_1/zeros_1, sequential_4/bidirectional_4/backward_lstm_4_1/strided_slice_1, sequential_4/bidirectional_4/backward_lstm_4_1/TensorArrayUnstack/TensorListFromTensor, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/kernel, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/recurrent_kernel, sequential_4/bidirectional_4/backward_lstm_4/lstm_cell_14/bias, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_1, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_2, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_3, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_4, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_5, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_6, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_7, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_8, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_9, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_10, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_11, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_12, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_13, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_14, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_15, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_16, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_17, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_18, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_19, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_20, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_21, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_22, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_23, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_24, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_25, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_26, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_27, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_28, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_29, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_30, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_31, sequential_4/bidirectional_4/backward_lstm_4_1/while/EmptyTensorList_32, training_2/Adam/gradients/gradients/sequential_4/bidirectional_4/backward_lstm_4_1/while_grad/gradients/TensorArrayV2Read/TensorListGetItem_grad/TensorListElementShape_0/accumulator:0, training_2/Adam/gradients/gradients/sequential_4/bidirectional_4/backward_lstm_4_1/while_grad/gradients/TensorArrayV2Read/TensorListGetItem_grad/TensorListLength_0/accumulator:0)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 98.98989898989899%\n"
     ]
    }
   ],
   "source": [
    "# Create the ART classifier\n",
    "classifier = KerasClassifier(model=model, use_logits=False)\n",
    "\n",
    "# Evaluate the ART classifier on benign test examples\n",
    "predictions = classifier.predict(X_valid)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(Y_valid, axis=1)) / len(Y_valid)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# set targeted label\n",
    "target = 2\n",
    "y_test_adv_tar = np.zeros(Y_valid.shape)\n",
    "for i in range(Y_valid.shape[0]):\n",
    "    y_test_adv_tar[i, target] = 1.0\n",
    "\n",
    "print(y_test_adv_tar[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import TargetedUniversalPerturbation\n",
    "\n",
    "adv_crafter = TargetedUniversalPerturbation(\n",
    "    classifier,\n",
    "    attacker='fgsm',\n",
    "    delta=0.2,\n",
    "    attacker_params={'eps':0.5, 'verbose': True},\n",
    "    max_iter=5,\n",
    "    eps=5.5,\n",
    "    norm=2)\n",
    "\n",
    "x_adv = adv_crafter.generate(x=X_valid, y=y_test_adv_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = adv_crafter.noise\n",
    "print(np.shape(noise))\n",
    "print(np.shape(X_valid))\n",
    "rescaled_noise = noise.copy()\n",
    "x_test_adv = X_valid + rescaled_noise\n",
    "preds_test_adv = np.argmax(classifier.predict(x_test_adv), axis=1) \n",
    "targeted_success_rate_test = np.sum(preds_test_adv == target) / len(X_valid) \n",
    "print('targeted_success_rate_test: {:.1f} %'.format(targeted_success_rate_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, accuracy] = model.evaluate(X_valid, Y_valid)\n",
    "\n",
    "Y_valid_predict = model.predict(X_valid)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(np.argmax(Y_valid_predict, axis=1), np.argmax(Y_valid, axis=1))\n",
    "plot_confusion_matrix(cm = matrix,\n",
    "                      target_names = ['Raise_arm', 'Run', 'Bow', 'Walk'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Universial Perturbation Through Deepfool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import TargetedUniversalPerturbation\n",
    "from art.utils import random_sphere\n",
    "\n",
    "# build targeted UAP\n",
    "classifier = KerasClassifier(model=model)\n",
    "adv_crafter = TargetedUniversalPerturbation(\n",
    "    classifier,\n",
    "    attacker='fgsm',\n",
    "    delta=0.000001,\n",
    "    attacker_params={'targeted':True, 'eps':0.006},\n",
    "    max_iter=10,\n",
    "    eps=5.5,\n",
    "    norm=2)\n",
    "\n",
    "\n",
    "# set target label\n",
    "target = 1\n",
    "y_train_adv_tar = np.zeros(Y_train.shape)\n",
    "for i in range(Y_train.shape[0]):\n",
    "    y_train_adv_tar[i, target] = 1.0\n",
    "\n",
    "# generate noise\n",
    "_ = adv_crafter.generate(X_train, y=y_train_adv_tar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(adv_crafter.noise))\n",
    "# noise = adv_crafter.noise[0,:]\n",
    "\n",
    "# X_train_adv = X_train + noise\n",
    "# X_valid_adv = X_valid + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, accuracy] = model.evaluate(X_dirty, Y_dirty)\n",
    "\n",
    "Y_dirty_predict = model.predict(X_dirty)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(np.argmax(Y_dirty, axis=1), np.argmax(Y_dirty_predict, axis=1))\n",
    "\n",
    "plot_confusion_matrix(cm = matrix,\n",
    "                      target_names = ['Raise_arm', 'Run', 'Bow', 'Walk'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, num_classes = generate_dataset('./usrp_dataset2/training/')\n",
    "\n",
    "norm_X = (X_train- mean)/std\n",
    "\n",
    "[loss, accuracy] = model.evaluate(norm_X, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('DNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_X, dirty_Y, num_classes = generate_dataset('./our_dataset/data/dirty')\n",
    "print(len(dirty_Y))\n",
    "\n",
    "model.evaluate(dirty_X, dirty_Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dirty_X)\n",
    "x = model.predict(dirty_X)\n",
    "print(np.argmax(x, axis=1))\n",
    "print(np.argmax(dirty_Y, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the adversarial sample\n",
    "\n",
    "### Implementing fast gradient sign method\n",
    "The first step is to create perturbations which will be used to distort the original CSI resulting in an adversarial image. As mentioned, for this task, the gradients are taken with respect to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_images, input_labels):\n",
    "\n",
    "  input_image = tf.convert_to_tensor(input_images, dtype=tf.float32)\n",
    "  input_label = tf.convert_to_tensor(input_labels, dtype=tf.float32)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "\n",
    "  fgm_grad= gradient / tf.norm(gradient, ord=2)\n",
    "\n",
    "  return signed_grad, fgm_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the original CSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "original_csis = X_valid\n",
    "original_targets = Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations1, perturbations2 = create_adversarial_pattern(original_csis, original_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_valid, y_valid):\n",
    "    y_pred = model.predict(x_valid)\n",
    "    y_predict = np.argmax(y_pred, axis=1)\n",
    "    y_valid_one = np.argmax(y_valid, axis=1)\n",
    "    accuracy = round(sum([y_ == y for y_, y in zip(y_predict, y_valid_one)])/len(y_valid_one) * 100,2)\n",
    "    print(\"accuracy: {}%\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epss = [];\n",
    "adv_accuracys = [];\n",
    "clean_accuracys = [];\n",
    "for eps in range(0, 11):\n",
    "    adv_x = original_csis\n",
    "    adv_x = adv_x + eps * perturbations1\n",
    "    # compute accuracy\n",
    "    acc = accuracy(adv_x, original_targets)\n",
    "    epss.append(eps/10)\n",
    "    adv_accuracys.append(acc)\n",
    "    clean_accuracys.append(98.46)\n",
    "    print(\"eps: {} ---> adv_acc:{}%\".format(eps, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean1 = plt.plot(epss, clean_accuracys, marker = 'v', linestyle = 'solid', label='Clean')\n",
    "adv1 = plt.plot(epss, adv_accuracys, marker = 'o', linestyle = 'solid', label='FGM')\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('UAP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7560b00439c9a18b07946e07b04233d01c8b203c21d1b1ada294496408168701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
